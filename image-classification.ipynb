{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Image classification with PyTorch & CNN"]},{"cell_type":"markdown","metadata":{},"source":["## Simple CNN Model Using PyTorch ##\n","\n","Simple notebook to do\n","   * simple data augmentation\n","   * Build a simple CNN model and train it\n","   * Predict test data Submit\n","\n","with pytorch"]},{"cell_type":"markdown","metadata":{},"source":["## Import Packages ##"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-05-15T05:07:37.379383Z","iopub.status.busy":"2022-05-15T05:07:37.378698Z","iopub.status.idle":"2022-05-15T05:07:39.576239Z","shell.execute_reply":"2022-05-15T05:07:39.574036Z","shell.execute_reply.started":"2022-05-15T05:07:37.3793Z"},"trusted":true},"outputs":[],"source":["from PIL import Image\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data import ConcatDataset\n","from torchvision.datasets import ImageFolder\n","from torchvision import transforms\n","from torch.utils.data import random_split\n","\n","import matplotlib.pyplot as plt\n","torch.manual_seed(17)"]},{"cell_type":"markdown","metadata":{},"source":["## Simple EDA ##\n","\n","We knows our dataset is Fashion-MNIST data, so there is remarks.\n","1. No class imbalance\n","2. All same image size\n","These makes us easy to use this dataset."]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-05-10T12:43:09.160529Z","iopub.status.busy":"2022-05-10T12:43:09.159786Z","iopub.status.idle":"2022-05-10T12:43:09.165019Z","shell.execute_reply":"2022-05-10T12:43:09.164175Z","shell.execute_reply.started":"2022-05-10T12:43:09.160479Z"}},"source":["## Build DataLoader ##"]},{"cell_type":"markdown","metadata":{},"source":["transforms is the module for image Transforming and Augmenting.\n","Can chain process using 'Compose'\n","\n","I thought below process will be needed.\n","* normalize\n","* Totensor"]},{"cell_type":"markdown","metadata":{},"source":["Pytorch officially use **(0.485, 0.456, 0.406), (0.229, 0.224, 0.225)**\n","instead of\n","(0.5, 0.5, 0.5),(0.5, 0.5, 0.5)\n","Those value is trained by ImageNet's mean and stddev\n","\n","> https://stackoverflow.com/questions/58151507/why-pytorch-officially-use-mean-0-485-0-456-0-406-and-std-0-229-0-224-0-2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T05:11:11.947425Z","iopub.status.busy":"2022-05-15T05:11:11.946921Z","iopub.status.idle":"2022-05-15T05:11:11.955442Z","shell.execute_reply":"2022-05-15T05:11:11.954345Z","shell.execute_reply.started":"2022-05-15T05:11:11.947393Z"},"trusted":true},"outputs":[],"source":["transform_normal=transforms.Compose([\n","      transforms.ToTensor(),\n","      transforms.RandomRotation([-60,60]),\n","      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n","])\n","transform_rotate=transforms.Compose([\n","    \n","      transforms.RandomRotation([-60,60]),\n","      transforms.ToTensor(),\n","      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","])\n","transform_horizontalflip=transforms.Compose([\n","    \n","      transforms.RandomHorizontalFlip(1),\n","      transforms.ToTensor(),\n","      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","])\n","transform_verticalflip=transforms.Compose([\n","      transforms.RandomVerticalFlip(1),\n","      transforms.ToTensor(),\n","      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","])"]},{"cell_type":"markdown","metadata":{},"source":["Dataset already includes base images, I flipped image for probability 1.\\"]},{"cell_type":"markdown","metadata":{},"source":["## Data Augmentation ##\n","Since there is not enough train_data set, Model needed much more dataset.\n","To solve this problem, pytorch provides data augmentation method such as transforsm.RandomRotation and etc.\n","\n","But Those method is in transform, which is used to make dataset.\n","So I selected to make several datasets and concat those with **torch.utils.data.ConcatDataset()**"]},{"cell_type":"markdown","metadata":{},"source":["And I used 3 transforms\n","* rotation\n","* horizontal_flip\n","* vertical_flip"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T02:33:59.038596Z","iopub.status.busy":"2022-05-15T02:33:59.037962Z","iopub.status.idle":"2022-05-15T02:34:11.239874Z","shell.execute_reply":"2022-05-15T02:34:11.239018Z","shell.execute_reply.started":"2022-05-15T02:33:59.038556Z"},"trusted":true},"outputs":[],"source":["dataset_normal = ImageFolder(root=\"/kaggle/input/devkor-image-classification/train\",\n","                      transform=transform_normal)\n","dataset_rotate = ImageFolder(root=\"/kaggle/input/devkor-image-classification/train\",\n","                      transform=transform_rotate)\n","dataset_horizontalflip = ImageFolder(root=\"/kaggle/input/devkor-image-classification/train\",\n","                      transform=transform_horizontalflip)\n","dataset_verticalflip = ImageFolder(root=\"/kaggle/input/devkor-image-classification/train\",\n","                      transform=transform_verticalflip)\n","\n","final_dataset = ConcatDataset([dataset_normal,dataset_rotate, dataset_horizontalflip, dataset_verticalflip])\n","# final_dataset = dataset_normal\n","dataloader = DataLoader(final_dataset, batch_size=128, shuffle=True, num_workers=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T02:34:11.243527Z","iopub.status.busy":"2022-05-15T02:34:11.24296Z","iopub.status.idle":"2022-05-15T02:34:11.251094Z","shell.execute_reply":"2022-05-15T02:34:11.250026Z","shell.execute_reply.started":"2022-05-15T02:34:11.243485Z"},"trusted":true},"outputs":[],"source":["print(len(final_dataset))"]},{"cell_type":"markdown","metadata":{},"source":["train_set, validation_set make"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T02:34:11.253681Z","iopub.status.busy":"2022-05-15T02:34:11.253044Z","iopub.status.idle":"2022-05-15T02:34:11.319741Z","shell.execute_reply":"2022-05-15T02:34:11.318995Z","shell.execute_reply.started":"2022-05-15T02:34:11.253642Z"},"trusted":true},"outputs":[],"source":["train_size = int(len(final_dataset)*0.8)\n","val_size = len(final_dataset) -  train_size\n","\n","train_dataset, val_dataset = random_split(final_dataset, [train_size, val_size])\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n","val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)"]},{"cell_type":"markdown","metadata":{},"source":["## Build CNN ##"]},{"cell_type":"markdown","metadata":{},"source":["very very simple cnn model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T02:34:11.321883Z","iopub.status.busy":"2022-05-15T02:34:11.321361Z","iopub.status.idle":"2022-05-15T02:34:11.331137Z","shell.execute_reply":"2022-05-15T02:34:11.330146Z","shell.execute_reply.started":"2022-05-15T02:34:11.321844Z"},"trusted":true},"outputs":[],"source":["class CNN(nn.Module):\n","    \n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        \n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","        \n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        \n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        \n","        self.layer4 = nn.Sequential(\n","            nn.Linear(2*2*256, 512),\n","            nn.Dropout(0.25),\n","            nn.Linear(512, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 10),\n","        )\n","\n","        \n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out.flatten(1))\n","        return out"]},{"cell_type":"markdown","metadata":{},"source":["If there exist gpu, use it"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T02:34:11.333241Z","iopub.status.busy":"2022-05-15T02:34:11.332786Z","iopub.status.idle":"2022-05-15T02:34:11.344886Z","shell.execute_reply":"2022-05-15T02:34:11.343869Z","shell.execute_reply.started":"2022-05-15T02:34:11.333201Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f\"[+] Train with {device}\")\n","\n","model = CNN().to(device)\n","criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T02:34:11.347249Z","iopub.status.busy":"2022-05-15T02:34:11.346784Z","iopub.status.idle":"2022-05-15T02:58:00.166444Z","shell.execute_reply":"2022-05-15T02:58:00.165519Z","shell.execute_reply.started":"2022-05-15T02:34:11.347207Z"},"trusted":true},"outputs":[],"source":["print(\"[+] Train Start\")\n","total_epochs = 50\n","\n","for epoch in range(total_epochs):\n","    train_l = []\n","    val_l = []\n","    for x, y in train_dataloader:\n","        model.train()\n","        \n","        x = x.to(device)\n","        y = y.to(device)\n","        y_pred = model(x)\n","        \n","        loss = criterion(y_pred, y)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_l.append(loss.detach().cpu())\n","        \n","    total = 0\n","    correct = 0\n","    for x, y in val_dataloader:\n","        x = x.to(device)\n","        y = y.to(device)\n","        y_pred = model(x)\n","        \n","        loss = criterion(y_pred, y)\n","        correct += (y_pred.argmax(dim=1) == y).sum().detach().cpu().item()\n","        total += len(y)\n","        \n","        val_l.append(loss.detach().cpu())\n","    print(f\"Epoch: {epoch}, Train Loss: {np.array(train_l).mean():.3f}, Val Loss: {np.array(val_l).mean():.3f}, Val Accuracy: {correct / total:.3f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T02:58:00.169311Z","iopub.status.busy":"2022-05-15T02:58:00.168306Z","iopub.status.idle":"2022-05-15T02:58:00.200007Z","shell.execute_reply":"2022-05-15T02:58:00.199235Z","shell.execute_reply.started":"2022-05-15T02:58:00.169235Z"},"trusted":true},"outputs":[],"source":["BASE_DIR = \"/kaggle/input/devkor-image-classification/test\"\n","\n","class TestDataset(Dataset):\n","    def __init__(self):\n","        super().__init__()\n","        self.file_list = [os.path.join(BASE_DIR, f\"{str(i).zfill(4)}.png\") for i in range(10000)]\n","        \n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, idx):\n","        img = Image.open(self.file_list[idx]).convert('RGB')\n","        return transform_normal(img)\n","\n","test_dataset = TestDataset()\n","test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T02:58:00.203Z","iopub.status.busy":"2022-05-15T02:58:00.202716Z","iopub.status.idle":"2022-05-15T02:59:04.846906Z","shell.execute_reply":"2022-05-15T02:59:04.845976Z","shell.execute_reply.started":"2022-05-15T02:58:00.202963Z"},"trusted":true},"outputs":[],"source":["pred = []\n","for x in test_dataloader:\n","    pred += model(x.to(device)).detach().cpu().argmax(dim=1).tolist()\n","print(len(pred))"]},{"cell_type":"markdown","metadata":{},"source":["## Submission ##"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T02:59:04.849894Z","iopub.status.busy":"2022-05-15T02:59:04.849443Z","iopub.status.idle":"2022-05-15T02:59:04.879758Z","shell.execute_reply":"2022-05-15T02:59:04.87903Z","shell.execute_reply.started":"2022-05-15T02:59:04.84985Z"},"trusted":true},"outputs":[],"source":["submission = pd.read_csv(\"/kaggle/input/devkor-image-classification/sample_submission.csv\")\n","submission.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T02:59:04.881254Z","iopub.status.busy":"2022-05-15T02:59:04.881011Z","iopub.status.idle":"2022-05-15T02:59:04.917392Z","shell.execute_reply":"2022-05-15T02:59:04.916547Z","shell.execute_reply.started":"2022-05-15T02:59:04.88122Z"},"trusted":true},"outputs":[],"source":["submission.loc[:, \"label\"] = pred\n","submission.to_csv(\"submission.csv\", index=False)\n","submission.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
